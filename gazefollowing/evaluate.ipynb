{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import itertools\n",
    "from scipy.io import  loadmat\n",
    "import logging\n",
    "from scipy import signal\n",
    "from utils import data_transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from models.gazenet import GazeNet\n",
    "from models.__init__ import save_checkpoint, resume_checkpoint\n",
    "from dataloader.gazenet import GooDataset, GazeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxes2centers(normalized_boxes):\n",
    "    \n",
    "    center_x = (normalized_boxes[:,0] + normalized_boxes[:,2]) / 2\n",
    "    center_y = (normalized_boxes[:,1] + normalized_boxes[:,3]) / 2\n",
    "    center_x = np.expand_dims(center_x, axis=1)\n",
    "    center_y = np.expand_dims(center_y, axis=1)\n",
    "    normalized_centers = np.hstack((center_x, center_y))\n",
    "    \n",
    "    return normalized_centers\n",
    "\n",
    "def select_nearest_bbox(gazepoint, gt_bboxes, gt_labels):\n",
    "    '''\n",
    "    In: Accepts gazepoint (2,) and bboxes (n_boxes, 4), normalized from [0,1]\n",
    "    Out: Returns the bbox nearest to gazepoint.\n",
    "    '''\n",
    "    \n",
    "    centers = boxes2centers(gt_bboxes)\n",
    "    \n",
    "    diff = centers - gazepoint\n",
    "    l2dist = np.sqrt(diff[:,0]**2 + diff[:,1]**2)\n",
    "    min_idx = l2dist.argmin()\n",
    "    \n",
    "    \n",
    "    nearest_box = {\n",
    "        'box' : gt_bboxes[min_idx],\n",
    "        'label': gt_labels[min_idx],\n",
    "        'index' : min_idx\n",
    "    }\n",
    "    return nearest_box\n",
    "\n",
    "# Precalculated mean box dimensions for GOO Objects\n",
    "#(0.044,0.074) - Synth\n",
    "# (0.013, 0.045)\n",
    "def point2box(point, mean_boxdims=(0.013, 0.045)):\n",
    "    \n",
    "    mbd = mean_boxdims\n",
    "    x1, y1 = point[0]-(mbd[0]/2), point[1]-(mbd[1]/2) #Upper left corner\n",
    "    x2, y2 = point[0]+(mbd[0]/2), point[1]+(mbd[1]/2) #Lower right corner\n",
    "    \n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def calculate_metrics(npzfile, dataset):\n",
    "    predictions = np.load(npzfile)\n",
    "    \n",
    "    error = []\n",
    "    percent_dists=[0.01, 0.03, 0.05, 0.10, 0.15, 0.20, 0.25, 0.3]\n",
    "    PA_count = np.zeros((len(percent_dists)))\n",
    "    \n",
    "    gazepoints = predictions['gazepoints']\n",
    "    \n",
    "    for idx, f_point in tqdm(enumerate(gazepoints), total=len(dataset)):\n",
    "        \n",
    "        data = dataset[idx]\n",
    "        \n",
    "        # Calculate L2, and use for pa/cpa\n",
    "        gt_point = data['gt_position'].numpy()\n",
    "        f_error = f_point - gt_point\n",
    "        f_dist = np.sqrt(f_error[0] ** 2 + f_error[1] ** 2)\n",
    "        error.append(f_dist)\n",
    "        \n",
    "        #Calc pa (corners)\n",
    "        gt_idx = data['gaze_idx']\n",
    "        gt_box = data['gt_bboxes'][gt_idx][:]\n",
    "        pred_box = point2box(f_point)\n",
    "        \n",
    "        dist_ul = np.sqrt((pred_box[0]-gt_box[0])** 2 + (pred_box[1]-gt_box[1])** 2)\n",
    "        dist_lr = np.sqrt((pred_box[2]-gt_box[2])** 2 + (pred_box[3]-gt_box[3])** 2)\n",
    "        corner_dist = (dist_ul + dist_lr) /2 \n",
    "\n",
    "        PA_count[np.array(percent_dists) > corner_dist] += 1     \n",
    "        \n",
    "    l2 = np.mean(np.array(error))\n",
    "    pa = PA_count / len(dataset)\n",
    "    metrics = {\n",
    "        'l2' : l2,\n",
    "        'pa' : pa,\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def calc_mean_boxdim(dataset):\n",
    "    \n",
    "    mean_dims = []\n",
    "    \n",
    "    for data in tqdm(dataset, total=len(dataset)):\n",
    "        \n",
    "        gt_idx = data['gaze_idx']\n",
    "        x1, y1, x2, y2 = data['gt_bboxes'][gt_idx][:]\n",
    "        \n",
    "        x_delta = x2 - x1\n",
    "        y_delta = y2 - y1\n",
    "        \n",
    "        mean_dims.append([x_delta, y_delta])\n",
    "        \n",
    "    mean_dims = np.mean(np.vstack(mean_dims), axis=0)\n",
    "\n",
    "    print(mean_dims)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Number of Images: 2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eee198/Documents/gaze-on-objects/gazefollowing/dataloader/gazenet.py:36: UserWarning: Enabling use_bboxes prevents this pytorch Dataset module to be used in the pytorch Dataloader module due to varying amount of bboxes in an image (Unstackable).\n",
      "  warnings.warn('Enabling use_bboxes prevents this pytorch Dataset module to be used in the pytorch Dataloader module due to varying amount of bboxes in an image (Unstackable).')\n"
     ]
    }
   ],
   "source": [
    "# REAL\n",
    "\n",
    "#Prepare dataloaders\n",
    "test_images_dir = '/home/eee198/Documents/datasets/GOOReal/finalrealdatasetImgsV2/'\n",
    "test_pickle_path = '/home/eee198/Documents/datasets/GOOReal/testrealhumans.pickle'\n",
    "batch_size = 16\n",
    "\n",
    "# Dataset\n",
    "val_set = GooDataset(test_images_dir, test_pickle_path, 'test', use_bboxes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 206/2156 [00:08<01:19, 24.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7c7d5f0ab08f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'predictions.npz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mPA_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L2 Distance: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1d6f20d2fde3>\u001b[0m in \u001b[0;36mcalculate_metrics\u001b[0;34m(npzfile, dataset)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgazepoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Calculate L2, and use for pa/cpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/gaze-on-objects/gazefollowing/dataloader/gazenet.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\\'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mflip_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions_path = 'predictions.npz'\n",
    "metrics = calculate_metrics(predictions_path, val_set)\n",
    "\n",
    "PA_count = metrics['pa']\n",
    "print('L2 Distance: ', metrics['l2'])\n",
    "print(\"Percentage Distances: \", [0.01, 0.03, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30])\n",
    "print(\"Proximate Accuracy: \\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t\"%\n",
    "            (PA_count[0],\n",
    "            PA_count[1],\n",
    "            PA_count[2],\n",
    "            PA_count[3],\n",
    "            PA_count[4],\n",
    "            PA_count[5],\n",
    "            PA_count[6],\n",
    "            PA_count[7],\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SYNTH\n",
    "\n",
    "#Prepare dataloaders\n",
    "test_images_dir = '/hdd/HENRI/goosynth/test/'\n",
    "test_pickle_path = '/hdd/HENRI/goosynth/picklefiles/testpickle120.pickle'\n",
    "batch_size = 16\n",
    "\n",
    "#For GOO\n",
    "val_set = GooDataset(test_images_dir, test_pickle_path, 'test', use_bboxes=True)\n",
    "val_set_load = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = torch.utils.data.DataLoader(val_set_load, batch_size=16, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PA_count = metrics['pa']\n",
    "print('L2 Distance: ', metrics['l2'])\n",
    "print(\"Percentage Distances: \", [0.01, 0.03, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30])\n",
    "print(\"Proximate Accuracy: \\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t\"%\n",
    "            (PA_count[0],\n",
    "            PA_count[1],\n",
    "            PA_count[2],\n",
    "            PA_count[3],\n",
    "            PA_count[4],\n",
    "            PA_count[5],\n",
    "            PA_count[6],\n",
    "            PA_count[7],\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_result(image_path, eye, heatmap, gaze_point, gt_point, idx=0):\n",
    "    x1, y1 = eye\n",
    "    x2, y2 = gaze_point\n",
    "    x3, y3 = gt_point\n",
    "    im = cv2.imread(image_path)\n",
    "    image_height, image_width = im.shape[:2]\n",
    "    x1, y1 = image_width * x1, y1 * image_height\n",
    "    x2, y2 = image_width * x2, y2 * image_height\n",
    "    x3, y3 = image_width * x3, y3 * image_height\n",
    "    x1, y1, x2, y2, x3, y3 = map(int, [x1, y1, x2, y2, x3, y3])\n",
    "    cv2.circle(im, (x1, y1), 5, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x2, y2), 5, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x3, y3), 5, [255, 255, 255], -1)\n",
    "    cv2.line(im, (x1, y1), (x2, y2), [255, 0, 0], 2)\n",
    "    cv2.line(im, (x1, y1), (x3, y3), [0, 165, 255], 2)\n",
    "\n",
    "    # heatmap visualization\n",
    "    heatmap = ((heatmap - heatmap.min()) / (heatmap.max() - heatmap.min()) * 255).astype(np.uint8)\n",
    "    heatmap = np.stack([heatmap, heatmap, heatmap], axis=2)\n",
    "    heatmap = cv2.resize(heatmap, (image_width, image_height))\n",
    "\n",
    "    heatmap = (0.8 * heatmap.astype(np.float32) + 0.2 * im.astype(np.float32)).astype(np.uint8)\n",
    "    img = np.concatenate((im, heatmap), axis=1)\n",
    "    \n",
    "    save_dir = './sample_out/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    filename = 'out_%s.png' % str(idx)\n",
    "    save_path = save_dir + filename\n",
    "    print(save_path)\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mean_boxdim(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_random(npzfile, dataset):\n",
    "    \n",
    "    # Load predictions from saved npz file\n",
    "    predictions = np.load(npzfile)\n",
    "    gazepoints = predictions['gazepoints']\n",
    "\n",
    "    # Get a random sample from dataset\n",
    "    idx = np.random.randint(len(dataset))\n",
    "    data = dataset[idx]\n",
    "\n",
    "    # Load data from the sample\n",
    "    image, face_image, gaze_field, eye_position = data['image'], data['face_image'], data['gaze_field'], data['eye_position']\n",
    "    image, face_image, gaze_field, eye_position = map(lambda x: Variable(x.cuda(), volatile=True), [image, face_image, gaze_field, eye_position])\n",
    "    gt_position = data['gt_position']\n",
    "    image_path = data['image_path']\n",
    "    gt_bboxes = data['gt_bboxes']\n",
    "    gt_labels = data['gt_labels']\n",
    "    \n",
    "    # Draw gazepoints and gt\n",
    "    im = cv2.imread(image_path)\n",
    "    image_height, image_width = im.shape[:2]\n",
    "    x1, y1 = eye_position\n",
    "    x2, y2 = gt_position\n",
    "    x3, y3 = gazepoints[idx]\n",
    "    x1, y1 = image_width * x1, y1 * image_height\n",
    "    x2, y2 = image_width * x2, y2 * image_height\n",
    "    x3, y3 = image_width * x3, y3 * image_height\n",
    "    x1, y1, x2, y2, x3, y3 = map(int, [x1, y1, x2, y2, x3, y3])\n",
    "    cv2.circle(im, (x1, y1), 5, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x2, y2), 5, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x3, y3), 5, [255, 255, 255], -1)\n",
    "    cv2.line(im, (x1, y1), (x2, y2), [255, 0, 0], 2) \n",
    "    cv2.line(im, (x1, y1), (x3, y3), [0, 165, 255], 2) \n",
    "\n",
    "    # Select nearest bbox given the gazepoint\n",
    "    gazepoint = gazepoints[idx]\n",
    "    #gt_bboxes = gt_bboxes / [image_width, image_height, image_width, image_height]\n",
    "    bbox_data = select_nearest_bbox(gazepoint, gt_bboxes, gt_labels)\n",
    "    nearest_bbox = bbox_data['box']\n",
    "\n",
    "    # Scale to image size\n",
    "    nearest_bbox = nearest_bbox * [image_width, image_height, image_width, image_height]\n",
    "    nearest_bbox = nearest_bbox.astype(int)\n",
    "\n",
    "    # Draw bbox of prediction\n",
    "    cv2.rectangle(im, (nearest_bbox[0], nearest_bbox[1]), (nearest_bbox[2], nearest_bbox[3]), (0,165,255), 2)\n",
    "    \n",
    "    # Draw bbox of gt\n",
    "    gaze_idx = data['gaze_idx']\n",
    "    box = gt_bboxes[gaze_idx]\n",
    "    nearest_bbox = box * [image_width, image_height, image_width, image_height]\n",
    "    nearest_bbox = nearest_bbox.astype(int)\n",
    "    cv2.rectangle(im, (nearest_bbox[0], nearest_bbox[1]), (nearest_bbox[2], nearest_bbox[3]), (255,0,0), 2)\n",
    "\n",
    "    img = im\n",
    "    save_dir = './temp/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    filename = 'out_%s.png' % str(1)\n",
    "    save_path = save_dir + filename\n",
    "    cv2.imwrite(save_path, img)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eee198/anaconda3/envs/gazefollow/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "demo_random('predictions.npz', val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './saved_models/gazenet_goo/model_epoch25.pth.tar'\n",
      "=> Optimizer has different parameter groups. Usually this will occur for staged optimizers (GazeNet, GazeMask)\n",
      "=> loaded checkpoint './saved_models/gazenet_goo/model_epoch25.pth.tar' (epoch 25)\n",
      "/home/eee198/Documents/gaze-on-objects/gazefollowing/dataloader/gazenet.py:36: UserWarning: Enabling use_bboxes prevents this pytorch Dataset module to be used in the pytorch Dataloader module due to varying amount of bboxes in an image (Unstackable).\n",
      "  warnings.warn('Enabling use_bboxes prevents this pytorch Dataset module to be used in the pytorch Dataloader module due to varying amount of bboxes in an image (Unstackable).')\n",
      "==> Number of Images: 19200\n"
     ]
    }
   ],
   "source": [
    "!python inference.py \\\n",
    "--test_dir='/hdd/HENRI/goosynth/test/'\\\n",
    "--test_annotation='/hdd/HENRI/goosynth/picklefiles/testpickle120.pickle'\\\n",
    "--resume_path='./saved_models/gazenet_goo/model_epoch25.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './saved_models/gazenet_goo/model_epoch25.pth.tar'\n",
      "=> Optimizer has different parameter groups. Usually this will occur for staged optimizers (GazeNet, GazeMask)\n",
      "=> loaded checkpoint './saved_models/gazenet_goo/model_epoch25.pth.tar' (epoch 25)\n",
      "/home/eee198/Documents/gaze-on-objects/gazefollowing/dataloader/gazenet.py:36: UserWarning: Enabling use_bboxes prevents this pytorch Dataset module to be used in the pytorch Dataloader module due to varying amount of bboxes in an image (Unstackable).\n",
      "  warnings.warn('Enabling use_bboxes prevents this pytorch Dataset module to be used in the pytorch Dataloader module due to varying amount of bboxes in an image (Unstackable).')\n",
      "==> Number of Images: 19200\n",
      "==> Number of Images: 19200\n",
      "==> No npzfile provided. Inference will be done on the test dataset and will be saved to predictions.npz\n",
      "100%|███████████████████████████████████████| 1200/1200 [08:55<00:00,  2.24it/s]\n",
      "==> Calculating eval metrics...\n",
      "100%|█████████████████████████████████████| 19200/19200 [07:45<00:00, 41.27it/s]\n",
      "AUC: 0.949743923611111\n",
      "L2 Distance:  0.10772794595155237\n",
      "Angular Error: 19.720474374658128\n",
      "Percentage Distances:  [0.01, 0.03, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
      "Proximate Accuracy: \t0.027\t0.173\t0.314\t0.542\t0.767\t0.903\t0.958\t0.978\t\n",
      "Class Proximate Accuracy: \t0.024\t0.147\t0.242\t0.318\t0.332\t0.334\t0.335\t0.336\t\n"
     ]
    }
   ],
   "source": [
    "!python evaluate.py \\\n",
    "--test_dir='/hdd/HENRI/goosynth/test/'\\\n",
    "--test_annotation='/hdd/HENRI/goosynth/picklefiles/testpickle120.pickle'\\\n",
    "--resume_path='./saved_models/gazenet_goo/model_epoch25.pth.tar'\\\n",
    "#--predictions_npz='./predictions.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
